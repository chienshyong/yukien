{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various feature extraction methods.\n",
    "\n",
    "At the bottom of this notebook, there is code to extract all these features and compile them into a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.976495462651123\n",
      "14.380766613498729\n",
      "10.316068510845778\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Detail metrics\n",
    "\n",
    "def edge_density(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    edges = cv2.Canny(img, 100, 200)\n",
    "    density = np.sum(edges > 0) / edges.size\n",
    "    return density\n",
    "\n",
    "def laplacian_variance(image_path):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return cv2.Laplacian(img, cv2.CV_64F).var()\n",
    "\n",
    "from skimage import io, color\n",
    "from skimage.measure import shannon_entropy\n",
    "\n",
    "def image_entropy(image_path):\n",
    "    img = io.imread(image_path)\n",
    "\n",
    "    # Handle alpha channel if present\n",
    "    if img.ndim == 3 and img.shape[2] == 4:  # RGBA\n",
    "        img = img[:, :, :3]  # Drop alpha\n",
    "\n",
    "    # Convert grayscale to 3-channel for consistency\n",
    "    if img.ndim == 2:\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "\n",
    "    # Normalize to [0, 1] and convert to grayscale\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    gray = color.rgb2gray(img)\n",
    "\n",
    "    return shannon_entropy(gray)\n",
    "\n",
    "img = rf'dataset/mery/danbooru_866364_32a36dadb2476488304e227fbc9be19e.png'\n",
    "print(image_entropy(img))\n",
    "img = rf'dataset\\torino\\danbooru_714868_f870a467b068f93c0fc9520ae800d74b.png'\n",
    "print(image_entropy(img))\n",
    "img = rf'dataset\\yukien\\danbooru_2754192_8695c575f852b9349acb1e90a3380fd8.png'\n",
    "print(image_entropy(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'avg_spread': 0.8854166666666666, 'avg_entropy': 2.225152314750004}\n",
      "{'avg_spread': 0.90625, 'avg_entropy': 2.743288423144755}\n",
      "{'avg_spread': 0.7395833333333334, 'avg_entropy': 2.0596846279298435}\n"
     ]
    }
   ],
   "source": [
    "# Color metrics\n",
    "\n",
    "# Hasler and Süsstrunk’s Colorfulness Metric\n",
    "def colorfulness(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    (B, G, R) = cv2.split(img.astype(\"float\"))\n",
    "    rg = np.absolute(R - G)\n",
    "    yb = np.absolute(0.5 * (R + G) - B)\n",
    "\n",
    "    std_rg, std_yb = np.std(rg), np.std(yb)\n",
    "    mean_rg, mean_yb = np.mean(rg), np.mean(yb)\n",
    "\n",
    "    return np.sqrt(std_rg**2 + std_yb**2) + 0.3 * np.sqrt(mean_rg**2 + mean_yb**2)\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# How evenly colors are distributed. High entropy = uniform spread\n",
    "# (no dominant color), low entropy = color is concentrated in few bins.\n",
    "def _histogram_spread(channel, bins=32):\n",
    "    hist, _ = np.histogram(channel, bins=bins, range=(0, 1), density=False)\n",
    "    non_zero_bins = np.count_nonzero(hist)\n",
    "    return non_zero_bins / bins  # value in [0, 1]\n",
    "\n",
    "def _histogram_entropy(channel, bins=32):\n",
    "    hist, _ = np.histogram(channel, bins=bins, range=(0, 1), density=True)\n",
    "    return entropy(hist + 1e-10)  # add epsilon to avoid log(0)\n",
    "\n",
    "def color_histogram_diversity(image_path, color_space='hsv', bins=32):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0\n",
    "\n",
    "    if color_space == 'hsv':\n",
    "        converted = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2HSV) / 255.0\n",
    "    elif color_space == 'lab':\n",
    "        converted = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_RGB2Lab) / 255.0\n",
    "    else:\n",
    "        raise ValueError(\"Choose 'hsv' or 'lab'.\")\n",
    "\n",
    "    diversity_metrics = []\n",
    "    for i in range(3):\n",
    "        channel = converted[:, :, i].flatten()\n",
    "        spread = _histogram_spread(channel, bins)\n",
    "        ent = _histogram_entropy(channel, bins)\n",
    "        diversity_metrics.append((spread, ent))\n",
    "\n",
    "    # Combine (you can weight them differently if needed)\n",
    "    avg_spread = np.mean([m[0] for m in diversity_metrics])\n",
    "    avg_entropy = np.mean([m[1] for m in diversity_metrics])\n",
    "    return {\n",
    "        \"avg_spread\": avg_spread,\n",
    "        \"avg_entropy\": avg_entropy\n",
    "    }\n",
    "    \n",
    "img = rf'dataset/mery/danbooru_866364_32a36dadb2476488304e227fbc9be19e.png'\n",
    "print(color_histogram_diversity(img))\n",
    "img = rf'dataset\\torino\\danbooru_714868_f870a467b068f93c0fc9520ae800d74b.png'\n",
    "print(color_histogram_diversity(img))\n",
    "img = rf'dataset\\yukien\\danbooru_2754192_8695c575f852b9349acb1e90a3380fd8.png'\n",
    "print(color_histogram_diversity(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temp_mean': 44.861831180811805, 'temp_stddev': 44.79717545504513}\n",
      "{'temp_mean': -21.360108333333333, 'temp_stddev': 41.90428196483342}\n",
      "{'temp_mean': 25.560463836477986, 'temp_stddev': 23.793796918470882}\n"
     ]
    }
   ],
   "source": [
    "# Temperature metrics\n",
    "\n",
    "# Computes the mean and stddev of color temps in an image, from -255 (blue) to 255 (red)\n",
    "def temperature_analysis(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert BGR to RGB (since OpenCV loads images in BGR format)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Extract Red and Blue channels\n",
    "    red_channel = image[:, :, 0].astype(np.int16)\n",
    "    blue_channel = image[:, :, 2].astype(np.int16)\n",
    "\n",
    "    # Compute difference (R - B)\n",
    "    diff = red_channel - blue_channel\n",
    "\n",
    "    # Compute statistics\n",
    "    temp_mean = np.mean(diff)\n",
    "    temp_stddev = np.std(diff)\n",
    "\n",
    "    return {\n",
    "        \"temp_mean\": temp_mean,\n",
    "        \"temp_stddev\": temp_stddev\n",
    "    }\n",
    "\n",
    "img = rf'dataset\\mery\\danbooru_866364_32a36dadb2476488304e227fbc9be19e.png'\n",
    "print(temperature_analysis(img))\n",
    "img = rf'dataset\\torino\\danbooru_714868_f870a467b068f93c0fc9520ae800d74b.png'\n",
    "print(temperature_analysis(img))\n",
    "img = rf'dataset\\yukien\\danbooru_2754192_8695c575f852b9349acb1e90a3380fd8.png'\n",
    "print(temperature_analysis(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_gray': 0.7696935, 'std_gray': 0.23083848}\n",
      "{'mean_gray': 0.6630832, 'std_gray': 0.32251438}\n",
      "{'mean_gray': 0.75510055, 'std_gray': 0.25526005}\n"
     ]
    }
   ],
   "source": [
    "# Values and Contrast metrics\n",
    "\n",
    "import numpy as np\n",
    "from skimage import io, color\n",
    "\n",
    "def grayscale_contrast_analysis(image_path):\n",
    "    # Load image\n",
    "    img = io.imread(image_path)\n",
    "\n",
    "    # Handle alpha channel or grayscale input\n",
    "    if img.ndim == 3 and img.shape[2] == 4:\n",
    "        img = img[:, :, :3]\n",
    "    elif img.ndim == 2:\n",
    "        img = np.stack([img]*3, axis=-1)\n",
    "\n",
    "    # Convert to grayscale [0, 1]\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    gray = color.rgb2gray(img)\n",
    "\n",
    "    # Compute mean and std deviation\n",
    "    mean_val = np.mean(gray)\n",
    "    std_val = np.std(gray)\n",
    "\n",
    "    return {\n",
    "        \"mean_gray\": mean_val,\n",
    "        \"std_gray\": std_val  # Higher = more contrast\n",
    "    }\n",
    "\n",
    "img = rf'dataset/mery/danbooru_866364_32a36dadb2476488304e227fbc9be19e.png'\n",
    "print(grayscale_contrast_analysis(img))\n",
    "img = rf'dataset\\torino\\danbooru_714868_f870a467b068f93c0fc9520ae800d74b.png'\n",
    "print(grayscale_contrast_analysis(img))\n",
    "img = rf'dataset\\yukien\\danbooru_2754192_8695c575f852b9349acb1e90a3380fd8.png'\n",
    "print(grayscale_contrast_analysis(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02940498 0.05232934 0.03541513 0.09476937 0.19600554 0.13138838\n",
      " 0.0466559  0.06144834 0.28041052 0.07217251]\n",
      "[0.05703333 0.07615833 0.03868333 0.09896667 0.19821667 0.12821667\n",
      " 0.05479167 0.08168333 0.14810833 0.11814167]\n",
      "[0.01967767 0.03600629 0.01407233 0.10430818 0.19987421 0.15391509\n",
      " 0.02926101 0.07389937 0.31221698 0.05676887]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chien Shyong\\AppData\\Roaming\\Python\\Python311\\site-packages\\skimage\\feature\\texture.py:353: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Local Binary Pattern\n",
    "\n",
    "from skimage import io, color, feature\n",
    "import numpy as np\n",
    "\n",
    "def compute_lbp_features(image_path, radius=1, n_points=8):\n",
    "    \"\"\"\n",
    "    Computes Local Binary Pattern (LBP) features for texture analysis.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path: Path to the input image.\n",
    "    - radius: Radius of circle for neighborhood.\n",
    "    - n_points: Number of points considered around each pixel (typically 8 * radius).\n",
    "\n",
    "    Returns:\n",
    "    - lbp_image: LBP-transformed image.\n",
    "    - histogram: Normalized histogram of LBP values (feature vector).\n",
    "    \"\"\"\n",
    "    # Load and convert to grayscale\n",
    "    img = io.imread(image_path)\n",
    "    # If the image has an alpha channel (RGBA), remove it and keep just RGB\n",
    "    if img.shape[2] == 4:\n",
    "        img = img[:, :, :3]  # Keep only the RGB channels\n",
    "    gray = color.rgb2gray(img)\n",
    "\n",
    "    # Compute LBP\n",
    "    lbp = feature.local_binary_pattern(gray, P=n_points, R=radius, method='uniform')\n",
    "\n",
    "    # Compute normalized histogram\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "\n",
    "    return hist\n",
    "\n",
    "img = rf'dataset/mery/danbooru_866364_32a36dadb2476488304e227fbc9be19e.png'\n",
    "print(compute_lbp_features(img))\n",
    "img = rf'dataset\\torino\\danbooru_714868_f870a467b068f93c0fc9520ae800d74b.png'\n",
    "print(compute_lbp_features(img))\n",
    "img = rf'dataset\\yukien\\danbooru_2754192_8695c575f852b9349acb1e90a3380fd8.png'\n",
    "print(compute_lbp_features(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0796619496855346, 776.7630187134113, 10.316068510845778, 29.93149043457331, 0.7395833333333334, 2.0596846279298435, 25.560463836477986, 23.793796918470882, 0.75510055, 0.25526005, 0.01967767295597484, 0.0360062893081761, 0.014072327044025158, 0.10430817610062892, 0.199874213836478, 0.15391509433962264, 0.029261006289308177, 0.07389937106918239, 0.31221698113207547, 0.0567688679245283]\n"
     ]
    }
   ],
   "source": [
    "# Compile everything\n",
    "def feature_extraction(image_path):\n",
    "    density = edge_density(image_path)\n",
    "    variance = laplacian_variance(image_path)\n",
    "    entropy = image_entropy(image_path)\n",
    "    colorful = colorfulness(image_path)\n",
    "    color_histogram = color_histogram_diversity(image_path)\n",
    "    temperature = temperature_analysis(image_path)\n",
    "    grayscale_contrast = grayscale_contrast_analysis(image_path)\n",
    "    lbp_features = compute_lbp_features(image_path)\n",
    "\n",
    "    result = [density, variance, entropy, colorful, color_histogram['avg_spread'], color_histogram['avg_entropy'],\n",
    "              temperature['temp_mean'], temperature['temp_stddev'], grayscale_contrast['mean_gray'], grayscale_contrast['std_gray']]\n",
    "    result += lbp_features.tolist()\n",
    "    return result\n",
    "\n",
    "image_path = rf'dataset/mery/danbooru_866364_32a36dadb2476488304e227fbc9be19e.png'\n",
    "print(feature_extraction(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 204/204 [00:30<00:00,  6.73it/s]\n",
      " 13%|█▎        | 172/1362 [00:16<01:34, 12.57it/s]c:\\Python311\\Lib\\site-packages\\PIL\\Image.py:975: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      " 50%|█████     | 682/1362 [01:11<00:52, 13.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6896507_01fe5370edf243fffe9a7746e1aa643d.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6897930_921c3741ca19929495331a1db4e03f23.png: the input array must have size 3 along `channel_axis`, got (356, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 693/1362 [01:12<00:38, 17.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6897937_710dbba1fb7894f936660af9270fbb72.png: the input array must have size 3 along `channel_axis`, got (1322, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6897938_a5f0a0e9e9f8a51ce358b3acef2e8477.png: the input array must have size 3 along `channel_axis`, got (1147, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6897939_21d08a4339f7e564b00ff03775bd7a78.png: the input array must have size 3 along `channel_axis`, got (1147, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6897940_65ef25a584cbf1bf0c63eadfbf2a7221.png: the input array must have size 3 along `channel_axis`, got (1147, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6897941_958eeb0db38e5c17bb0aaa0adf25f9eb.png: the input array must have size 3 along `channel_axis`, got (1147, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6897942_ec4342644d45d9add7fdd6c672f3c050.png: the input array must have size 3 along `channel_axis`, got (1147, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 704/1362 [01:13<00:48, 13.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6898040_3c41a1fdc853c45bf3682852a5565277.png: the input array must have size 3 along `channel_axis`, got (1176, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6898043_463cea9ed6fa86fb44414704682b1611.png: the input array must have size 3 along `channel_axis`, got (989, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6898045_1cbcb08f7c7ec1674691c721de34b188.png: the input array must have size 3 along `channel_axis`, got (370, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6898046_cf442d0b02f82c2b7693af1c25c75dc0.png: the input array must have size 3 along `channel_axis`, got (362, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 709/1362 [01:13<00:34, 18.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6898047_6806fe324be26199c10c5a2a23086730.png: the input array must have size 3 along `channel_axis`, got (1125, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6898048_875068adcece4ca7a5dbaf238ba76da2.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 763/1362 [01:18<00:40, 14.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6904942_e34c76155c82613cf436dcd7ca7ece92.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6904943_7dd4e5bb37108e244da1a44c4e056d6c.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 859/1362 [01:26<00:40, 12.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6921486_0234ce284084fe626ddaefb2d6868422.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 865/1362 [01:26<00:29, 16.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6925346_4d5557f2271c063e9ef687baeb194cd2.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6925347_796c632649bd1464c403a54d8bae744d.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6925360_5d0d838c20fa550aa10290e59fe9c0e8.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6925361_734f13d1e487cf23be91ce356b8d25c1.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 928/1362 [01:32<00:28, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6944864_660fe1a48c484b376299b4e087078c69.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6944866_d8fc0868badbfa815c48a0f9edad1104.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n",
      "Error processing dataset/yukien\\danbooru_6944886_ebd1bacbcc0c205572191be82f584ee7.png: the input array must have size 3 along `channel_axis`, got (564, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 1006/1362 [01:38<00:28, 12.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing dataset/yukien\\danbooru_6955238_f211d3d67a77c40bcfd4cd757bfe784a.png: the input array must have size 3 along `channel_axis`, got (287, 400, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362/1362 [02:17<00:00,  9.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# image_path, artist_label, edge_density, laplacian_variance, shannon_entropy, hs_colorfulness, color_spread, color_entropy, \n",
    "# temp_mean, temp_stddev, gray_mean, gray_stddev, lbp_0, lbp_1, lbp_2, lbp_3, lbp_4, lbp_5, lbp_6, lbp_7, lbp_8, lbp_9\n",
    "\n",
    "import os\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "\n",
    "def insert_into_csv(image_path, artist, output_file='dataset.csv'):\n",
    "    try:\n",
    "        features = feature_extraction(image_path)\n",
    "        data = [image_path, artist] + features\n",
    "\n",
    "        # Append the list as a new row\n",
    "        with open(output_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(data)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "def process_folder(folder_path, artist_label, output_file='dataset.csv'):\n",
    "    image_files = [f for f in os.listdir(folder_path)]\n",
    "    for image_name in tqdm(image_files):\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "        insert_into_csv(image_path, artist_label, output_file)\n",
    "\n",
    "process_folder(rf'dataset/mery', 0)\n",
    "process_folder(rf'dataset/torino', 1)\n",
    "process_folder(rf'dataset/yukien', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
